{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht-ThfGZ6rcz"
      },
      "source": [
        "# Pathology Deep Learning Hands-On\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/KatherLab/stamp_demo/blob/master/stamp_hands_on.ipynb)\n",
        "\n",
        "Welcome to the 2025 Clinicum Digitale digital pathology hands-on session.\n",
        "In this session we will have a look at what a typical machine learning workflow in our lab looks like.\n",
        "We will predict the TP53 gene alteration in breast cancer from histopathologic whole-slide images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV8acwCned1u"
      },
      "source": [
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl9Y_hE2htyh"
      },
      "source": [
        "## 1. Change runtime type\n",
        "First, switch to a GPU-enabled Colab runtime: within Google Colab, go to *Runtime* $\\to$ *Change runtime type*, and select **, as indicated in the screenshot below.\n",
        "\n",
        "<img src=\"https://github.com/KatherLab/stamp_demo/blob/master/colab_runtime.png?raw=true\" width=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2tgNtonho7l"
      },
      "source": [
        "## 2. Install dependencies\n",
        "Here, we will install [STAMP](https://github.com/KatherLab/STAMP), a pipeline for computational pathology developed in [our lab](https://jnkather.github.io/)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"stamp @ git+https://github.com/KatherLab/STAMP@feature/validation-config\""
      ],
      "metadata": {
        "id": "24S9MP3Wgmwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to a weird bug in Google Colab, please now restart the kernel (*Runtime* $\\to$ *Restart session*), and continue from here."
      ],
      "metadata": {
        "id": "2OYbq5BirY7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning  # if this throws an error, please restart the kernel"
      ],
      "metadata": {
        "id": "-ZxEslmcn9jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmRLQ52UiVMN"
      },
      "source": [
        "## 3. Download data\n",
        "Let's download our dataset of extracted features. This will take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyPzxx-8iYHV"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from tqdm.notebook import tqdm\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "\n",
        "_DOWNLOAD_PARTS = {\n",
        "    \"TCGA_BRCA_10x_UNI_features.tar.gz.part_aa\": \"6ff1600f3dcdc6344d3a5c46eca481c4\",\n",
        "    \"TCGA_BRCA_10x_UNI_features.tar.gz.part_ab\": \"7b4c7bb21ac365ee86be86e10f6e4efa\",\n",
        "}\n",
        "\n",
        "\n",
        "def md5(fname: str, chunk_size=8192) -> str:\n",
        "    hash_md5 = hashlib.md5()\n",
        "    with open(fname, \"rb\") as f:\n",
        "        while chunk := f.read(chunk_size):\n",
        "            hash_md5.update(chunk)\n",
        "    return hash_md5.hexdigest()\n",
        "\n",
        "\n",
        "def download(url: str, output_file: Path, checksum: str, chunk_size=1024):\n",
        "    if output_file.exists():\n",
        "        if md5(output_file) == checksum:\n",
        "            print(f\"{output_file} already downloaded, skipping...\")\n",
        "            return\n",
        "        else:\n",
        "            output_file.unlink()\n",
        "\n",
        "    resp = requests.get(url, stream=True)\n",
        "    total = int(resp.headers.get(\"content-length\", 0))\n",
        "    with (\n",
        "        output_file.open(\"wb\") as f,\n",
        "        tqdm(\n",
        "            desc=str(output_file),\n",
        "            total=total,\n",
        "            unit=\"iB\",\n",
        "            unit_scale=True,\n",
        "            unit_divisor=1024,\n",
        "        ) as bar,\n",
        "    ):\n",
        "        for data in resp.iter_content(chunk_size=chunk_size):\n",
        "            size = f.write(data)\n",
        "            bar.update(size)\n",
        "\n",
        "\n",
        "if not Path(\"TCGA_BRCA_10x_UNI_features.tar.gz\").exists():\n",
        "    for filename, checksum in _DOWNLOAD_PARTS.items():\n",
        "        download(\n",
        "            f\"https://github.com/KatherLab/stamp_demo/releases/download/data-release/{filename}\",\n",
        "            Path(filename),\n",
        "            checksum,\n",
        "        )\n",
        "\n",
        "    !cat TCGA_BRCA_10x_UNI_features.tar.gz.part_* > TCGA_BRCA_10x_UNI_features.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uX0KBKV9cGM"
      },
      "source": [
        "Now, let's extract the tar archive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74bESBtl8gF-"
      },
      "outputs": [],
      "source": [
        "!test -d TCGA_BRCA_10x_UNI_features || \\\n",
        "    (mkdir -p TCGA_BRCA_10x_UNI_features && \\\n",
        "     tar -xzf TCGA_BRCA_10x_UNI_features.tar.gz -C TCGA_BRCA_10x_UNI_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI6lCMeo-DeS"
      },
      "source": [
        "As a sanity check, ensure there are exactly `242` files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4VKjUn7-IAF"
      },
      "outputs": [],
      "source": [
        "!ls TCGA_BRCA_10x_UNI_features | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgRN1KCiyWmp"
      },
      "source": [
        "# Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G37hHEMyX8o"
      },
      "source": [
        "## From whole slide image to classification output\n",
        "\n",
        "Our goal is to classify whole slide images (WSIs).\n",
        "In particular, we want to train a deep learning model that given a WSI, predicts the presence of a genetic mutation in TP53.\n",
        "In other words, our model will map a whole slide image (in $\\mathbb{R}^{H \\times W \\times 3}$) to a scalar prediction (in $[0,1]$).\n",
        "To do this, we follow a multi-step workflow consisting of:\n",
        "1. split whole slide image into tiles\n",
        "2. extract features\n",
        "3. aggregate features\n",
        "4. classify\n",
        "\n",
        "The workflow can be summarised as:\n",
        "$$\n",
        "\\mathbb{R}^{H \\times W \\times 3}\n",
        "\\xrightarrow{\\text{tiling}} \\mathbb{R}^{n \\times p \\times p \\times 3}\n",
        "\\xrightarrow{\\text{extract features}} \\mathbb{R}^{n \\times d}\n",
        "\\xrightarrow{\\text{aggregate}} \\mathbb{R}^{1 \\times d}\n",
        "\\xrightarrow{\\text{classify}} [0, 1]\n",
        "$$\n",
        "where $H,W$ are the dimensions of the original whole slide image,\n",
        "$p=224$ is the patch size, and\n",
        "$d=1024$ is the dimensionality of the feature extractor.\n",
        "\n",
        "<img src=\"https://github.com/georg-wolflein/good-features/blob/master/assets/overview.png?raw=true\" width=800 />\n",
        "\n",
        "\n",
        "For simplicity, we will only do the **downstream training** part in this notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyiq7jdxIiVu"
      },
      "source": [
        "## The structure of our data\n",
        "\n",
        "Let's first have a look at our data.\n",
        "The dataset we are using today consists of three major components:\n",
        "\n",
        "1. The clini table contains clinical data for each patient\n",
        "2. The slide table maps each slide a patient\n",
        "3. The slide features contain a condensed, machine-learning-ready representation of the slides"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAERMAKiEQFg"
      },
      "source": [
        "### Clini table\n",
        "\n",
        "The clini table contains clinical information for each patient.\n",
        "Each row of the clini table describes exactly one patient.\n",
        "\n",
        "* The column `PATIENT` contains a patient ID in the form `TCGA-site-patient` (`site` tells us which hostpital the patient is from)\n",
        "* The remaining columns contain other clinical information on the patient\n",
        "  * Among these, the `TP53` column indicates if there is a mutation of TP53. We will try to predict this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCh9kid32Cvp"
      },
      "outputs": [],
      "source": [
        "!test -f TCGA-BRCA-DX_CLINI.csv || wget https://raw.githubusercontent.com/KatherLab/stamp_demo/refs/heads/master/TCGA-BRCA-DX_CLINI.csv -q -O TCGA-BRCA-DX_CLINI.csv\n",
        "\n",
        "import pandas as pd\n",
        "clini_df = pd.read_csv(\"TCGA-BRCA-DX_CLINI.csv\")\n",
        "clini_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN7yHS3-J8Cd"
      },
      "source": [
        "### Slide table\n",
        "We often have multiple slides per patient.\n",
        "The slide table matches each slide to its patient.\n",
        "If a patient has multiple slides, it will appear multiple times, once for each slide they have."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-87kpi_Vx1t"
      },
      "outputs": [],
      "source": [
        "!test -f TCGA-BRCA-DX_SLIDE.csv || wget https://raw.githubusercontent.com/KatherLab/stamp_demo/refs/heads/master/TCGA-BRCA-DX_SLIDE.csv -q -O TCGA-BRCA-DX_SLIDE.csv\n",
        "slide_df = pd.read_csv(\"TCGA-BRCA-DX_SLIDE.csv\")\n",
        "slide_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCvBJl8LKRz_"
      },
      "outputs": [],
      "source": [
        "for _, row in (\n",
        "    slide_df.groupby(\"PATIENT\").nunique().value_counts().reset_index().iterrows()\n",
        "):\n",
        "    print(f\"{row['count']:3d} patients have {row['FILENAME']} slides\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zucMb51BLH72"
      },
      "source": [
        "### Features\n",
        "Finally, we have the slide features themselves.\n",
        "Since whole slide images are large, too large to do machine learning on them directly, we first reduce them to a more managable form with a feature extractor.\n",
        "The feature extractor is itself a neural network.\n",
        "It takes a whole slide image and reduces it to a more condensed form.\n",
        "While the exact mechanism by which it does so is outside the scope of this course, it compresses the size of an input 10-fold, allowing us to use neural networks to analyze them.\n",
        "\n",
        "Since this process does take quite some time, we have already extracted the features for today's dataset in advance.\n",
        "Let's have a look at the features for one particular whole slide image.\n",
        "\n",
        "Below is a thumbnail of this WSI. We removed background areas (shown in red).\n",
        "\n",
        "![Slide Image](https://raw.githubusercontent.com/KatherLab/stamp_demo/refs/heads/master/TCGA-BH-A0HU-01Z-00-DX1.73B38904-E4F8-4F45-BD75-A27EC833B6DE.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cV2jhI-m5haY"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "\n",
        "with h5py.File(\n",
        "    \"TCGA_BRCA_10x_UNI_features/TCGA-BH-A0HU-01Z-00-DX1.73B38904-E4F8-4F45-BD75-A27EC833B6DE.h5\",\n",
        "    \"r\",\n",
        ") as f:\n",
        "    feats = f[\"feats\"][:]\n",
        "    coords = f[\"coords\"][:]\n",
        "    print(\"Shape of features array:\", feats.shape)\n",
        "    print(\"Shape of coordinates array:\", coords.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mBHx-XL5haY"
      },
      "source": [
        "As we can see, we have $n=5597$ feature vectors in this slide. This means that the WSI was split into 5597 patches. From each patch, we extracted a $d=1024$ dimensional feature vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKsiPRNe5haY"
      },
      "source": [
        "#### Features\n",
        "Let's have a look at one of the feature vectors. As we will see, it consists of 1024 floating point numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwAsedNl5haY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(feats[0])\n",
        "plt.figure(figsize=(10, 2))\n",
        "plt.bar(range(1024), feats[0])\n",
        "plt.xlabel(\"Feature dimension\")\n",
        "plt.ylabel(\"Feature value\")\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8dW_7o35haY"
      },
      "source": [
        "#### Coordinates\n",
        "Let's also visualize the coordinates of the patches. We will see the shape of the WSI. Compare this to the image of the WSI above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFhBLhy95haY"
      },
      "outputs": [],
      "source": [
        "plt.plot(coords[:, 0], coords[:, 1], \"o\", markersize=1)\n",
        "plt.xlabel(\"x coordinate\")\n",
        "plt.ylabel(\"y coordinate\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.axis(\"equal\")\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqQ9UeAs5haY"
      },
      "source": [
        "## Splitting our data\n",
        "\n",
        "We will split our dataset into two subsets: one part for training, one for testing.\n",
        "Specifically, we will use patients from the largest site as the training set and the second largest site as the test set.\n",
        "\n",
        "Often times, pathological slides contain artifacts like staining differences that make it possible to infer where slides originate from.\n",
        "If certain hospitals have for example a higher rate of severe cases, the network may be base its prediction based on these artifacts instead of actually medically relevant features.\n",
        "By ensuring that our testing set is from another site, we will be able to determine if our network is able to generalize to new sites."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK:**\n",
        "Split `clini_df` and `slide_df` into a train and test set. The train set should contain all patients from the site `\"BH\"`, and the test set should contain all patients from the site `\"A2\"`.\n",
        "\n",
        "You should create four dataframes:\n",
        "1. `train_clini_df`\n",
        "2. `train_slide_df`\n",
        "3. `test_clini_df`\n",
        "4. `test_slide_df`\n",
        "\n",
        "Hint: the Patient IDs are in the format `TCGA-site-ID`."
      ],
      "metadata": {
        "id": "drYca5lnTxb8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ov7uV1vb5haY"
      },
      "outputs": [],
      "source": [
        "# Insert your code here...\n",
        "\n",
        "\n",
        "train_clini_df = ...\n",
        "train_slide_df = ...\n",
        "test_clini_df = ...\n",
        "test_slide_df = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save the dataframes as CSV."
      ],
      "metadata": {
        "id": "o7k1y6G4Tl1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_clini_df.to_csv(\"TCGA-BRCA-DX_CLINI_train.csv\", index=False)\n",
        "train_slide_df.to_csv(\"TCGA-BRCA-DX_SLIDE_train.csv\", index=False)\n",
        "test_clini_df.to_csv(\"TCGA-BRCA-DX_CLINI_test.csv\", index=False)\n",
        "test_slide_df.to_csv(\"TCGA-BRCA-DX_SLIDE_test.csv\", index=False)\n",
        "\n",
        "print(f\"Training set: {len(train_clini_df)} patients\")\n",
        "print(f\"Testing set: {len(test_clini_df)} patients\")\n",
        "train_clini_df"
      ],
      "metadata": {
        "id": "5D0KUS3xTun-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q0B-j9R-Jnx"
      },
      "source": [
        "## Inspecting our data\n",
        "\n",
        "Before starting training any models, it is often worth it to inspect the data to ensure that there are no glaring problems with it.\n",
        "Let's look at the TP53 column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nYYi2cl-rNa"
      },
      "outputs": [],
      "source": [
        "train_clini_df[\"TP53\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in7cubn7_bln"
      },
      "source": [
        "As we can see, one class is less frequent than the other.\n",
        "This can lead to problems while training our network.\n",
        "Why becomes intuitively apparent if you consider a strongly imbalanced dataset with only two classes, one making up 90% of the dataset.\n",
        "The network can trivially reach an accuracy of 90% by just always chosing the more frequent class.\n",
        "\n",
        "One approach to combat this is to weigh the classes.\n",
        "In STAMP, the classes are automatically weighed in such a way that each class has the overall same contribution.\n",
        "For a nine-to-one imbalanced two-class dataset, each instance of the rare class would thus be weighted as having nine times the importance of a sample of the more common class.\n",
        "\n",
        "This can of course still lead to instabilities in training, especially if one of the rare classes is one we don't particularly care about.\n",
        "In that case the network may spend too much time learning how to correctly classify the unimportant class at the cost of more interesting classes.\n",
        "\n",
        "However, we should be fine here because the imbalance isn't too severe.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSlT5QpkLg7G"
      },
      "source": [
        "# Training a model\n",
        "\n",
        "We will now train our model. This will take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8awOFfXuPgit"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from stamp.modeling.train import train_categorical_model_\n",
        "import torch\n",
        "\n",
        "output_dir = Path(\"output\")\n",
        "output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "train_categorical_model_(\n",
        "    output_dir=output_dir,\n",
        "    clini_table=Path(\"TCGA-BRCA-DX_CLINI_train.csv\"),\n",
        "    slide_table=Path(\"TCGA-BRCA-DX_SLIDE_train.csv\"),\n",
        "    feature_dir=Path(\"TCGA_BRCA_10x_UNI_features\"),\n",
        "    patient_label=\"PATIENT\",\n",
        "    ground_truth_label=\"TP53\",\n",
        "    filename_label=\"FILENAME\",\n",
        "    categories=[\"0\", \"1\"],\n",
        "    # Dataset and -loader parameters\n",
        "    bag_size=512,\n",
        "    val_bag_size=2048,\n",
        "    num_workers=min(os.cpu_count() or 1, 16),\n",
        "    # Training paramenters\n",
        "    batch_size=64,\n",
        "    max_epochs=64,\n",
        "    patience=16,\n",
        "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "    # Experimental features\n",
        "    use_vary_precision_transform=False,\n",
        "    use_alibi=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the training and validation loss."
      ],
      "metadata": {
        "id": "uj3SO5jGk9nw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLMGmLoGICuX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lightning_logs_dir = sorted(output_dir.joinpath(\"lightning_logs\").glob(\"version_*\"))[-1]\n",
        "\n",
        "history = pd.read_csv(lightning_logs_dir / \"metrics.csv\")\n",
        "history = history.groupby([\"epoch\", \"step\"]).first().reset_index()\n",
        "history.plot(x=\"epoch\", y=[\"training_loss\", \"validation_loss\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1jWW6FRpN--"
      },
      "source": [
        "As we can see, the training loss decreases a lot faster and further than the validation loss.\n",
        "This is to be expected:\n",
        "since the network is trained on the training set, it does not only learn to recognize features relevant for classifying the target, but also learns to recognize the training images themselves.\n",
        "\n",
        "Many of the features the network learns will not generalize.\n",
        "In general, the longer we train a network, the more likely it is that it will pick up small, non-generalizing details uniquely identifying a singular image from the training set.\n",
        "This is why we have a validation set:\n",
        "By checking how well the network performs on the validation set, we can determine whether the network is still learning generalizable features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwGzdSlKIfyK"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.validation_auroc)\n",
        "plt.title(\"Validation ROC AUC Score\")\n",
        "plt.xlabel(\"Epoch\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZgzfYQ6sHt4"
      },
      "source": [
        "The same should be visible in the AUROC over the progress of the training:\n",
        "initially, the ROC AUC score on the validation drops sharply while the network learns to recognize well-generalizing featues.\n",
        "Then, as these easy-to-recognize features have been exhausted, improvement quickly becomes slower and stagnates.\n",
        "\n",
        "If we train for too long, the performance on the validation set may even regress, as the only thing the network is doing during training is learning how to best classify the training set and one way of doing that is to just \"memorize\" all the specific training samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EkAOkI4RUgS"
      },
      "source": [
        "# Deploying our model on external data\n",
        "\n",
        "**As soon as we use the testing set, we are not allowed to change the experimental setup any more**.\n",
        "\n",
        "We will now _deploy_ our model on the testing set, that is, see how well it can predict never-before seen data.\n",
        "This is different from our validation set in that, while the network was not _trained_ on the validation data, we did determine which epoch's model was the best based on the validation set.\n",
        "Furthermore, parts of the validation set were sampled from the same cohorts as the training set.\n",
        "We can thus expect the validation set to be more akin to the training set, and thus expect the network to perform better for the validation set than the testing set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stamp.modeling.deploy import deploy_categorical_model_\n",
        "\n",
        "deploy_categorical_model_(\n",
        "    output_dir=output_dir,\n",
        "    checkpoint_paths=[output_dir / \"model.ckpt\"],\n",
        "    clini_table=Path(\"TCGA-BRCA-DX_CLINI_test.csv\"),\n",
        "    slide_table=Path(\"TCGA-BRCA-DX_SLIDE_test.csv\"),\n",
        "    feature_dir=Path(\"TCGA_BRCA_10x_UNI_features\"),\n",
        "    patient_label=\"PATIENT\",\n",
        "    ground_truth_label=\"TP53\",\n",
        "    filename_label=\"FILENAME\",\n",
        "    num_workers=min(os.cpu_count() or 1, 16),\n",
        "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "    bag_size=2048\n",
        ")"
      ],
      "metadata": {
        "id": "5BqSQ6JEsdDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a look at the predictions that the model makes on the test set."
      ],
      "metadata": {
        "id": "erzSx8iiq_VO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = pd.read_csv(output_dir / \"patient-preds.csv\")\n",
        "pred_df = pred_df[~pred_df.TP53.isna()]  # remove rows with unknown groundtruth\n",
        "pred_df = pred_df.rename(columns={\"TP53_1\": \"TP53_pred\"})[[\"PATIENT\", \"TP53\", \"TP53_pred\"]]\n",
        "pred_df"
      ],
      "metadata": {
        "id": "CKUAqiXlxCae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCsZval44JtH"
      },
      "source": [
        "As you can see, the neural network actually doesn't give us a decision, but a probability for our classes.\n",
        "Depending on what we use the network for, it may actually be useful to select a higher or lower threshold:\n",
        "for a screening test for example we may use a very low threshold to ensure that we definitely include all patients that have a specific illness.\n",
        "\n",
        "One tool that can help us qualify the quality of our classifier is the Receiver-Operator-Characteristic Curve, or ROC-Curve for short:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stamp.statistics.roc import plot_single_decorated_roc_curve\n",
        "\n",
        "plot_single_decorated_roc_curve(\n",
        "    ax=plt.gca(),\n",
        "    y_true=(pred_df.TP53 == 1.).values,\n",
        "    y_score=pred_df.TP53_pred.values,\n",
        "    n_bootstrap_samples=1000,\n",
        "    threshold_cmap=None,\n",
        "    title=\"TP53\",\n",
        ")"
      ],
      "metadata": {
        "id": "xnyiWVN9snYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7dPLLMW0sON"
      },
      "source": [
        "The ROC curve plots the true positive rate (also called specificity) against the false positive rate (1 - sensitivity).\n",
        "We can evidently force our classifier to have perfect sensitivity by classifying _every_ sample as positive (i.e. setting the classification to 0).\n",
        "Similarly, we can make its specificity perfect by classifying every sample as false.\n",
        "Clearly, these classifiers are not particularly useful.\n",
        "The ROC curve shows us, how sensitivity and specificity fluctuate for different cutoffs.\n",
        "The area under that curve (AUC) is often used as a quick-and-easy way to compare classifiers' performance.\n",
        "For a more detailed explanation, check out [this visual explanation of ROC curves](https://mlu-explain.github.io/roc-auc/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdKvttn7UppL"
      },
      "source": [
        "While ROC curves are one of the major endpoints for judging the quality of a classifier, they have one problem to be aware of, especially if the question of applicability of machine learning in the real world comes up.\n",
        "A ROC curve only contrasts the models sensitivity with specificity.\n",
        "This means that, as long as the model is able to separate the classes in a dataset, it will maintain a relatively high ROC.\n",
        "While this does show that the features learned by our network _are_ transferable, it can still pose problems when actually deploying our model.\n",
        "\n",
        "Often times, artifacts introduced by the way histopathological slides are prepared in a hospital can consistently affect how the network classifies a sample.\n",
        "A difference in staining for example may consistenly cause samples to be scored too highly.\n",
        "This means that for example the threshold we selected to reach a certain sensitivity may not be transferable between our validation and training set."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus\n",
        "\n",
        "If you have time, complete the two tasks below.\n",
        "\n",
        "*Hint:* Use ChatGPT to help you code --- we use it in the lab all the time:)"
      ],
      "metadata": {
        "id": "K-oaKJFomqGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge 1: computing statistics at a threshold"
      ],
      "metadata": {
        "id": "FLFKQfYbBm7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title { run: \"auto\" }\n",
        "#@markdown Move the slider to see how the threshold (decision boundary) impacts accuracy.\n",
        "threshold = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "probabilities = pred_df.TP53_pred.values\n",
        "predictions = probabilities >= threshold\n",
        "groundtruth = pred_df.TP53.values == 1.\n",
        "\n",
        "accuracy_score = (predictions == groundtruth).mean()\n",
        "print(f\"Accuracy: {accuracy_score:.2f}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vGVJLVyq-W_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write code in the cell below to compute the following metrics on the test set:\n",
        "- sensitivity (true positive rate)\n",
        "- specificity (true negative rate)\n",
        "\n",
        "\n",
        "*Hints*:\n",
        "- Use the code for computing accuracy above for inspiration\n",
        "- Inspect the contents of the `probabilities`, `predictions` and `groundtruth` variables."
      ],
      "metadata": {
        "id": "LSoMsnLVABCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_positives = ...\n",
        "true_negatives = ...\n",
        "\n",
        "sensitivity = ...\n",
        "specificity = ...\n",
        "\n",
        "print(f\"Sensitivity: {sensitivity}\")\n",
        "print(f\"Specificity: {specificity}\")"
      ],
      "metadata": {
        "id": "ogjYDqXgBTpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge 2: plot the precision recall curve\n",
        "\n",
        "Use `matplotlib` to plot the precision recall curve."
      ],
      "metadata": {
        "id": "9RxqHY4bCTQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert code here...\n",
        "\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "8fomGobOCPLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge 3: dummy classifier\n",
        "\n",
        "Earlier we talked about the dangers of imbalanced datasets.\n",
        "Imagine we had a model that always predicts `TP53 = 1` no matter its input.\n",
        "Write code to compute how this \"dummy classifier\" would fare on the test set, regarding:\n",
        "- accuracy\n",
        "- balanced accuracy\n",
        "- sensitivity\n",
        "- specificity"
      ],
      "metadata": {
        "id": "ZWG1dswKClNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here..."
      ],
      "metadata": {
        "id": "FHEIBvYeDTTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKHKmGq4kIhz"
      },
      "source": [
        "This concludes our hands-on for deep learning in histopathology.\n",
        "As you have seen, deep learning can be used to answer a variety of histopathological questions.\n",
        "However, while current research is promising, there are still a lot of steps remaining to make it a reliable part of medical practice."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "EmRLQ52UiVMN"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}